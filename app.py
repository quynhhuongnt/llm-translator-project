import streamlit as st
import google.generativeai as genai
import easyocr
from PIL import Image
import numpy as np
import docx
import PyPDF2
from io import StringIO

# 1. C·∫§U H√åNH TRANG & CSS (Gi·ªØ nguy√™n giao di·ªán c·ªßa b·∫°n)
st.set_page_config(page_title="LLM Cloud Translator", layout="wide", page_icon="üåê")

st.markdown("""
<style>
    .stTextArea textarea { font-size: 16px; height: 300px; font-family: sans-serif; }
    .stButton button { 
        background-color: #1a73e8; color: white; font-size: 16px; 
        border-radius: 8px; padding: 0.5rem 1rem; border: none; 
        width: 100%; font-weight: bold;
    }
    .stButton button:hover { background-color: #1557b0; color: white; }
    .result-box { 
        border: 1px solid #d3d3d3; border-radius: 0.5rem; padding: 1rem;             
        height: 300px; background-color: #f0f2f6; color: #31333F;           
        overflow-y: auto; font-family: sans-serif; font-size: 16px;          
        white-space: pre-wrap; user-select: text; cursor: text;               
    }
    header {visibility: hidden;}
    footer {visibility: hidden;}
    .lang-header { font-weight: bold; font-size: 18px; margin-bottom: 10px; display: block; color: #1a73e8; }
</style>
""", unsafe_allow_html=True)

# 2. BACKEND LOGIC
@st.cache_resource
def load_ocr():
    # Th√™m tham s·ªë gpu=False v√¨ Streamlit Cloud kh√¥ng c√≥ GPU mi·ªÖn ph√≠
    return easyocr.Reader(['en'], gpu=False)

# Kh·ªüi t·∫°o model b√™n ngo√†i h√†m ƒë·ªÉ tr√°nh g·ªçi l·∫°i nhi·ªÅu l·∫ßn
def get_gemini_model():
    try:
        api_key = st.secrets["GEMINI_API_KEY"]
        genai.configure(api_key=api_key)
        # S·ª≠a l·ªói NotFound b·∫±ng c√°ch ch·ªâ ƒë·ªãnh ch√≠nh x√°c phi√™n b·∫£n
        return genai.GenerativeModel('gemini-1.5-flash')
    except Exception as e:
        st.error(f"L·ªói c·∫•u h√¨nh API: {e}")
        return None

model = get_gemini_model()
reader = load_ocr()

# T·ªëi ∆∞u h√†m d·ªãch: S·ª≠ d·ª•ng streaming ƒë·ªÉ tr√°nh timeout tr√™n Cloud
def translate_with_llm(text, type_context="vƒÉn b·∫£n"):
    if not text or not text.strip(): return ""
    prompt = f"B·∫°n l√† chuy√™n gia d·ªãch thu·∫≠t. H√£y d·ªãch ƒëo·∫°n {type_context} sau sang ti·∫øng Vi·ªát m·ªôt c√°ch t·ª± nhi√™n: \n\n{text}"
    
    try:
        # S·ª≠ d·ª•ng stream=True ƒë·ªÉ nh·∫≠n d·ªØ li·ªáu li√™n t·ª•c, tr√°nh b·ªã ƒë·ª©ng app
        response = model.generate_content(prompt, stream=True)
        full_text = ""
        # T·∫°o placeholder ƒë·ªÉ hi·ªán ch·ªØ ch·∫°y d·∫ßn d·∫ßn (UX t·ªët h∆°n)
        with st.empty():
            for chunk in response:
                full_text += chunk.text
                # Ch·ªâ hi·ªÉn th·ªã t·∫°m th·ªùi ·ªü ƒë√¢y n·∫øu b·∫°n mu·ªën hi·ªáu ·ª©ng g√µ ch·ªØ
        return full_text
    except Exception as e:
        return f"L·ªói d·ªãch thu·∫≠t: {str(e)}"

def read_file(uploaded_file):
    text = ""
    try:
        if uploaded_file.type == "text/plain":
            text = StringIO(uploaded_file.getvalue().decode("utf-8")).read()
        elif uploaded_file.type == "application/pdf":
            pdf_reader = PyPDF2.PdfReader(uploaded_file)
            for page in pdf_reader.pages:
                extracted = page.extract_text()
                if extracted: text += extracted + "\n"
        elif "word" in uploaded_file.type or "officedocument" in uploaded_file.type:
            doc = docx.Document(uploaded_file)
            for para in doc.paragraphs:
                text += para.text + "\n"
    except Exception as e:
        st.error(f"L·ªói ƒë·ªçc file: {e}")
    return text

# 3. FRONTEND
st.title(" ·ª®NG D·ª§NG D·ªäCH ANH - VI·ªÜT CLOUD LLM ")
st.markdown("Sinh vi√™n th·ª±c hi·ªán: Ng√¥ Th·ªã Qu·ª≥nh H∆∞∆°ng | M√£ SV: 99048")

tab_text, tab_image, tab_doc = st.tabs(["üî§ VƒÉn B·∫£n", "üì∏ H√¨nh ·∫¢nh", "üìÇ T√†i Li·ªáu"])

# Kh·ªüi t·∫°o session state
for key in ['res_text', 'res_img', 'res_doc']:
    if key not in st.session_state: st.session_state[key] = ""

with tab_text:
    c1, c2 = st.columns(2)
    with c1:
        st.markdown('<span class="lang-header">TI·∫æNG ANH</span>', unsafe_allow_html=True)
        t_input = st.text_area("Input", height=300, label_visibility="collapsed", key="input_area")
    with c2:
        st.markdown('<span class="lang-header">TI·∫æNG VI·ªÜT (AI)</span>', unsafe_allow_html=True)
        st.markdown(f'<div class="result-box">{st.session_state.res_text}</div>', unsafe_allow_html=True)
    
    if st.button("D·ªäCH NGAY", key="btn1"):
        if t_input:
            with st.spinner("ƒêang d·ªãch..."):
                st.session_state.res_text = translate_with_llm(t_input)
                st.rerun()

with tab_image:
    c1, c2 = st.columns(2)
    with c1:
        img_file = st.file_uploader("Ch·ªçn ·∫£nh", type=['png','jpg','jpeg'], label_visibility="collapsed")
        if img_file: st.image(Image.open(img_file), use_container_width=True)
    with c2:
        st.markdown(f'<div class="result-box">{st.session_state.res_img}</div>', unsafe_allow_html=True)
    
    if st.button("QU√âT & D·ªäCH", key="btn2"):
        if img_file:
            with st.spinner("ƒêang qu√©t ·∫£nh v√† d·ªãch..."):
                img_np = np.array(Image.open(img_file))
                res_ocr = reader.readtext(img_np, detail=0)
                raw_ocr = " ".join(res_ocr)
                st.session_state.res_img = translate_with_llm(raw_ocr, "qu√©t t·ª´ ·∫£nh")
                st.rerun()

with tab_doc:
    doc_file = st.file_uploader("Ch·ªçn file", type=['pdf','docx','txt'], label_visibility="collapsed")
    if st.button("D·ªäCH T√ÄI LI·ªÜU", key="btn3"):
        if doc_file:
            with st.spinner("ƒêang x·ª≠ l√Ω t√†i li·ªáu..."):
                content = read_file(doc_file)
                st.session_state.res_doc = translate_with_llm(content, "t√†i li·ªáu")
                st.rerun()
    
    if st.session_state.res_doc:
        st.markdown(f'<div class="result-box">{st.session_state.res_doc}</div>', unsafe_allow_html=True)
