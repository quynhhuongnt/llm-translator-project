import streamlit as st
import google.generativeai as genai
import easyocr
from PIL import Image
import numpy as np
import docx
import PyPDF2
from io import StringIO

# 1. C·∫§U H√åNH TRANG & GIAO DI·ªÜN CSS
st.set_page_config(page_title="H∆∞∆°ng Ng√¥ - AI Translator", layout="wide", page_icon="üåê")

st.markdown("""
<style>
    .stTextArea textarea { font-size: 16px; height: 300px; font-family: sans-serif; }
    .stButton button { 
        background-color: #1a73e8; color: white; font-size: 16px; 
        border-radius: 8px; padding: 0.5rem 1rem; border: none; 
        width: 100%; font-weight: bold;
    }
    .stButton button:hover { background-color: #1557b0; color: white; }
    .result-box { 
        border: 1px solid #d3d3d3; border-radius: 0.5rem; padding: 1rem;             
        height: 300px; background-color: #f8f9fa; color: #31333F;           
        overflow-y: auto; font-family: sans-serif; font-size: 16px;          
        white-space: pre-wrap;
    }
    header {visibility: hidden;}
    footer {visibility: hidden;}
    .lang-header { font-weight: bold; font-size: 18px; margin-bottom: 10px; display: block; color: #1a73e8; }
</style>
""", unsafe_allow_html=True)

# 2. KH·ªûI T·∫†O C√îNG C·ª§ (BACKEND)
@st.cache_resource
def load_ocr():
    # Ch·∫°y tr√™n CPU c·ªßa Streamlit Cloud n√™n t·∫Øt GPU
    return easyocr.Reader(['en'], gpu=False)

def get_model():
    try:
        # L·∫•y API Key t·ª´ Secrets (C·∫ßn c√†i ƒë·∫∑t tr√™n Streamlit Cloud Settings)
        api_key = st.secrets["GEMINI_API_KEY"]
        genai.configure(api_key=api_key)
        # S·ª≠ d·ª•ng phi√™n b·∫£n ·ªïn ƒë·ªãnh nh·∫•t ƒë·ªÉ tr√°nh l·ªói 404
        return genai.GenerativeModel('gemini-1.5-flash')
    except Exception as e:
        st.error(f"L·ªói c·∫•u h√¨nh API Key: {e}")
        return None

model = get_model()
reader = load_ocr()

# 3. H√ÄM X·ª¨ L√ù LOGIC
def translate_stream(text, context="vƒÉn b·∫£n"):
    if not text.strip(): return
    prompt = f"B·∫°n l√† chuy√™n gia d·ªãch thu·∫≠t. H√£y d·ªãch ƒëo·∫°n {context} sau sang ti·∫øng Vi·ªát m·ªôt c√°ch t·ª± nhi√™n v√† l∆∞u lo√°t: \n\n{text}"
    try:
        # S·ª≠ d·ª•ng stream ƒë·ªÉ hi·ªán ch·ªØ ch·∫°y d·∫ßn d·∫ßn, tr√°nh timeout
        response = model.generate_content(prompt, stream=True)
        for chunk in response:
            yield chunk.text
    except Exception as e:
        yield f"‚ö†Ô∏è L·ªói k·∫øt n·ªëi API: {str(e)}"

def read_file_content(uploaded_file):
    text = ""
    try:
        if uploaded_file.type == "text/plain":
            text = StringIO(uploaded_file.getvalue().decode("utf-8")).read()
        elif uploaded_file.type == "application/pdf":
            pdf = PyPDF2.PdfReader(uploaded_file)
            for page in pdf.pages:
                text += page.extract_text() + "\n"
        elif "word" in uploaded_file.type or "officedocument" in uploaded_file.type:
            doc = docx.Document(uploaded_file)
            for para in doc.paragraphs:
                text += para.text + "\n"
    except Exception as e:
        st.error(f"L·ªói ƒë·ªçc t√†i li·ªáu: {e}")
    return text

# 4. GIAO DI·ªÜN NG∆Ø·ªúI D√ôNG (FRONTEND)
st.title("üöÄ ·ª®NG D·ª§NG D·ªäCH ANH - VI·ªÜT CLOUD LLM")
st.markdown("**Sinh vi√™n th·ª±c hi·ªán:** Ng√¥ Th·ªã Qu·ª≥nh H∆∞∆°ng | **M√£ SV:** 99048")
st.divider()

tab1, tab2, tab3 = st.tabs(["üî§ VƒÉn B·∫£n", "üì∏ H√¨nh ·∫¢nh", "üìÇ T√†i Li·ªáu"])

# Kh·ªüi t·∫°o tr·∫°ng th√°i l∆∞u tr·ªØ
if 'res_text' not in st.session_state: st.session_state.res_text = ""

# TAB 1: D·ªäCH VƒÇN B·∫¢N
with tab1:
    c1, c2 = st.columns(2)
    with c1:
        st.markdown('<span class="lang-header">TI·∫æNG ANH</span>', unsafe_allow_html=True)
        t_input = st.text_area("Input", height=300, label_visibility="collapsed", key="txt_in")
    with c2:
        st.markdown('<span class="lang-header">TI·∫æNG VI·ªÜT (AI STREAMING)</span>', unsafe_allow_html=True)
        # S·ª≠ d·ª•ng container ƒë·ªÉ hi·ªán k·∫øt qu·∫£ streaming
        res_placeholder = st.empty()
        res_placeholder.markdown(f'<div class="result-box">{st.session_state.res_text}</div>', unsafe_allow_html=True)

    if st.button("D·ªäCH NGAY", key="btn_text"):
        if t_input:
            st.session_state.res_text = "" # Reset k·∫øt qu·∫£ c≈©
            full_res = ""
            for chunk in translate_stream(t_input):
                full_res += chunk
                res_placeholder.markdown(f'<div class="result-box">{full_res}</div>', unsafe_allow_html=True)
            st.session_state.res_text = full_res

# TAB 2: D·ªäCH H√åNH ·∫¢NH
with tab2:
    col_img, col_res = st.columns(2)
    with col_img:
        st.markdown('<span class="lang-header">T·∫¢I ·∫¢NH L√äN</span>', unsafe_allow_html=True)
        img_file = st.file_uploader("Upload", type=['png','jpg','jpeg'], label_visibility="collapsed")
        if img_file: st.image(img_file, use_container_width=True)
    
    with col_res:
        st.markdown('<span class="lang-header">K·∫æT QU·∫¢ QU√âT & D·ªäCH</span>', unsafe_allow_html=True)
        res_img_place = st.empty()
        res_img_place.markdown('<div class="result-box"></div>', unsafe_allow_html=True)

    if st.button("B·∫ÆT ƒê·∫¶U QU√âT & D·ªäCH", key="btn_img"):
        if img_file:
            with st.spinner("ƒêang nh·∫≠n di·ªán ch·ªØ..."):
                img_np = np.array(Image.open(img_file))
                ocr_text = " ".join(reader.readtext(img_np, detail=0))
            
            full_img_res = f"**N·ªôi dung nh·∫≠n di·ªán:** {ocr_text}\n\n**B·∫£n d·ªãch:**\n"
            temp_res = ""
            for chunk in translate_stream(ocr_text, "t·ª´ h√¨nh ·∫£nh"):
                temp_res += chunk
                res_img_place.markdown(f'<div class="result-box">{full_img_res + temp_res}</div>', unsafe_allow_html=True)

# TAB 3: D·ªäCH T√ÄI LI·ªÜU
with tab3:
    doc_file = st.file_uploader("Ch·ªçn file (PDF, DOCX, TXT)", type=['pdf','docx','txt'])
    if st.button("D·ªäCH TO√ÄN B·ªò FILE", key="btn_doc"):
        if doc_file:
            with st.spinner("ƒêang ƒë·ªçc v√† d·ªãch t√†i li·ªáu..."):
                content = read_file_content(doc_file)
                res_doc_place = st.empty()
                full_doc_res = ""
                for chunk in translate_stream(content, "t√†i li·ªáu"):
                    full_doc_res += chunk
                    res_doc_place.markdown(f'<div class="result-box">{full_doc_res}</div>', unsafe_allow_html=True)
