import streamlit as st
import time
import torch
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import easyocr
from PIL import Image
import numpy as np
import docx
import PyPDF2
from io import StringIO, BytesIO

# 1. C·∫§U H√åNH TRANG
st.set_page_config(page_title="Deep Learning Translator", layout="wide", page_icon="üá¨üáßüáªüá≥")

# 2. CSS CUSTOM
st.markdown("""
<style>
    .stTextArea textarea { 
        font-size: 16px; 
        height: 300px; 
        font-family: sans-serif;
    }
    
    .stButton button { 
        background-color: #1a73e8; 
        color: white; 
        font-size: 16px; 
        border-radius: 8px; 
        padding: 0.5rem 1rem; 
        border: none; 
        width: 100%; 
        font-weight: bold;
    }
    .stButton button:hover { background-color: #1557b0; color: white; }
    
    .result-box { 
        border: 1px solid #d3d3d3; 
        border-radius: 0.5rem;      
        padding: 1rem;             
        height: 300px;              
        background-color: #f0f2f6;  
        color: #31333F;           
        overflow-y: auto;         
        font-family: sans-serif;   
        font-size: 16px;          
        white-space: pre-wrap;      
        user-select: text;          
        cursor: text;               
    }
    
    header {visibility: hidden;}
    footer {visibility: hidden;}
    
    .lang-header {
        font-weight: bold;
        font-size: 18px;
        margin-bottom: 10px;
        display: block;
        color: #1a73e8;
    }
</style>
""", unsafe_allow_html=True)

# 3. BACKEND - X·ª¨ L√ù M√î H√åNH V√Ä LOGIC

@st.cache_resource
def load_models():
    # Load Model D·ªãch (EnViT5)
    model_name = "VietAI/envit5-translation"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model = model.to(device)
    
    # Load Model OCR (EasyOCR)
    reader = easyocr.Reader(['en'], gpu=(device == "cuda"))
    
    return tokenizer, model, reader, device

try:
    tokenizer, model, reader, device = load_models()
except Exception as e:
    st.error(f"L·ªói t·∫£i model: {e}")

def translate_text(text):
    if not text or text.strip() == "": return ""
    input_text = "en: " + text
    inputs = tokenizer(input_text, return_tensors="pt", padding=True, truncation=True, max_length=512).to(device)
    with torch.no_grad():
        output_ids = model.generate(
            inputs.input_ids,
            max_length=512,
            num_beams=4,
            early_stopping=True
        )
    return tokenizer.decode(output_ids[0], skip_special_tokens=True).replace("vi: ", "")

def split_and_translate(text):
    chunks = text.split('\n')
    translated_chunks = []
    temp_chunk = ""
    for chunk in chunks:
        # Gi·ªõi h·∫°n token ƒë·ªÉ tr√°nh qu√° t·∫£i m√¥ h√¨nh (kho·∫£ng 500 k√Ω t·ª± m·ªói l·∫ßn d·ªãch)
        if len(temp_chunk) + len(chunk) < 500:
            temp_chunk += chunk + "\n"
        else:
            translated_chunks.append(translate_text(temp_chunk))
            temp_chunk = chunk + "\n"
    if temp_chunk:
        translated_chunks.append(translate_text(temp_chunk))
    return "\n".join(translated_chunks)

def read_file(uploaded_file):
    text = ""
    if uploaded_file.type == "text/plain":
        stringio = StringIO(uploaded_file.getvalue().decode("utf-8"))
        text = stringio.read()
    elif uploaded_file.type == "application/pdf":
        pdf_reader = PyPDF2.PdfReader(uploaded_file)
        for page in pdf_reader.pages:
            extracted = page.extract_text()
            if extracted: text += extracted + "\n"
    elif "word" in uploaded_file.type:
        doc = docx.Document(uploaded_file)
        for para in doc.paragraphs:
            text += para.text + "\n"
    return text

def create_docx(text):
    """H√†m t·∫°o file Word t·ª´ n·ªôi dung vƒÉn b·∫£n"""
    doc = docx.Document()
    for line in text.split('\n'):
        doc.add_paragraph(line)
    
    bio = BytesIO()
    doc.save(bio)
    return bio.getvalue()

# 4. FRONTEND - GIAO DI·ªÜN NG∆Ø·ªúI D√ôNG

st.title(" ·ª®NG D·ª§NG D·ªäCH ANH - VI·ªÜT S·ª¨ D·ª§NG M√î H√åNH LLM ")
st.markdown("**M√¥n:** Kƒ© thu·∫≠t h·ªçc s√¢u v√† ·ª©ng d·ª•ng")
st.markdown("**Sinh vi√™n th·ª±c hi·ªán:** Ng√¥ Th·ªã Qu·ª≥nh H∆∞∆°ng | **MSV:** 99048")

tab_text, tab_image, tab_doc = st.tabs(["üî§ VƒÉn B·∫£n", "üì∏ H√¨nh ·∫¢nh", "üìÇ T√†i Li·ªáu"])

# Kh·ªüi t·∫°o session state
if 'trans_text' not in st.session_state: st.session_state.trans_text = ""
if 'trans_img' not in st.session_state: st.session_state.trans_img = ""
if 'trans_doc' not in st.session_state: st.session_state.trans_doc = ""

# TAB 1: D·ªäCH VƒÇN B·∫¢N TR·ª∞C TI·∫æP
with tab_text:
    st.write("") 
    c1, c2 = st.columns(2)
    with c1:
        st.markdown('<span class="lang-header">TI·∫æNG ANH</span>', unsafe_allow_html=True)
        text_input = st.text_area("Input", height=300, placeholder="Nh·∫≠p vƒÉn b·∫£n ti·∫øng Anh t·∫°i ƒë√¢y...", label_visibility="collapsed")
        
    with c2:
        st.markdown('<span class="lang-header">TI·∫æNG VI·ªÜT</span>', unsafe_allow_html=True)
        result_content = st.session_state.trans_text if st.session_state.trans_text else ""
        st.markdown(f'<div class="result-box">{result_content}</div>', unsafe_allow_html=True)

    st.write("")
    if st.button("D·ªäCH VƒÇN B·∫¢N", key="btn_text"):
        if text_input:
            with st.spinner("AI ƒëang d·ªãch..."):
                st.session_state.trans_text = translate_text(text_input)
                st.rerun()

# TAB 2: D·ªäCH QUA H√åNH ·∫¢NH (OCR)
with tab_image:
    st.write("")
    c1, c2 = st.columns(2)
    with c1:
        st.markdown('<span class="lang-header">T·∫¢I ·∫¢NH L√äN</span>', unsafe_allow_html=True)
        uploaded_img = st.file_uploader("", type=['png', 'jpg', 'jpeg'], key="upload_img", label_visibility="collapsed")
        if uploaded_img:
            image = Image.open(uploaded_img)
            st.image(image, caption="·∫¢nh g·ªëc", use_container_width=True)

    with c2:
        st.markdown('<span class="lang-header">K·∫æT QU·∫¢ D·ªäCH</span>', unsafe_allow_html=True)
        content_img = st.session_state.trans_img if st.session_state.trans_img else ""
        st.markdown(f'<div class="result-box">{content_img}</div>', unsafe_allow_html=True)
    
    st.write("")
    if st.button("QU√âT & D·ªäCH ", key="btn_img"):
        if uploaded_img:
            with st.spinner("ƒêang nh·∫≠n di·ªán ch·ªØ v√† d·ªãch..."):
                img_np = np.array(image)
                res = reader.readtext(img_np, detail=0)
                extracted_text = " ".join(res)
                translated = translate_text(extracted_text)
                st.session_state.trans_img = f"VƒÇN B·∫¢N NH·∫¨N DI·ªÜN:\n{extracted_text}\n\nB·∫¢N D·ªäCH:\n{translated}"
                st.rerun()

# TAB 3: D·ªäCH T√ÄI LI·ªÜU V√Ä T·∫¢I V·ªÄ .DOCX
with tab_doc:
    st.write("")
    c1, c2 = st.columns(2)
    with c1:
        st.markdown('<span class="lang-header">T·∫¢I FILE (WORD/PDF/TXT)</span>', unsafe_allow_html=True)
        uploaded_doc = st.file_uploader("", type=['docx', 'pdf', 'txt'], key="upload_doc", label_visibility="collapsed")
        if uploaded_doc:
            st.success(f"ƒê√£ nh·∫≠n file: {uploaded_doc.name}")

    with c2:
        st.markdown('<span class="lang-header">N·ªòI DUNG D·ªäCH</span>', unsafe_allow_html=True)
        content_doc = st.session_state.trans_doc if st.session_state.trans_doc else "K·∫øt qu·∫£ s·∫Ω hi·ªán ·ªü ƒë√¢y..."
        display_text = content_doc[:2000] + ("..." if len(content_doc) > 2000 else "")
        st.markdown(f'<div class="result-box">{display_text}</div>', unsafe_allow_html=True)

    st.write("")
    if st.button("D·ªäCH TO√ÄN B·ªò T√ÄI LI·ªÜU", key="btn_doc"):
        if uploaded_doc:
            with st.spinner("ƒêang x·ª≠ l√Ω file l·ªõn, vui l√≤ng ƒë·ª£i..."):
                raw_text = read_file(uploaded_doc)
                full_translated_text = split_and_translate(raw_text)
                st.session_state.trans_doc = full_translated_text
                st.rerun()
    
    # N√∫t t·∫£i v·ªÅ d·∫°ng .docx
    if st.session_state.trans_doc:
        docx_file = create_docx(st.session_state.trans_doc)
        st.download_button(
            label="üìÑ T·∫£i b·∫£n d·ªãch (.docx)",
            data=docx_file,
            file_name="translated_document.docx",
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
        )
